# Assignment Feedback: Week 04 Dimensionality Reduction

**Student:** praveerbn
**Raw Score:** 49/50 (98.0%)
**Course Points Earned:** 108.0

---

## Problem Breakdown

### Exercise 2 (10/10 = 100.0%)

**Part ex1-part1** (ex1-part1.code): 4/4 points

_Feedback:_ Good job: you sampled a subset, applied t-SNE with sensible params, and plotted colored by labels. This meets the goal. For clarity, consider adding a colorbar and an explicit colormap. Otherwise, solid and correct implementation.

**Part ex1-part2** (ex1-part2.code): 3/3 points

_Feedback:_ Good use of t-SNE + KNN and you reported accuracy. One caveat: you fit t-SNE on the combined train+test set, which leaks test info. Prefer fitting on train only and transforming test. Otherwise solid approach aligned with the task.

**Part ex1-part3** (ex1-part3.code): 3/3 points

_Feedback:_ Good job: you used UMAP embeddings for train/test, fit KNN, and reported accuracy via .score. This matches the task and prior work. Using 30D is fine. No issues detected.

---

### Exercise 4 (19/20 = 95.0%)

**Part ex2-part1** (ex2-part1.code): 7/7 points

_Feedback:_ Excellent. You applied PCA with multiple component choices, trained KNN on the transformed data, reported test accuracy, and visualized the first two PCs colored by labels. This meets the task requirements. Nice work.

**Part ex2-part2** (ex2-part2.code): 7/7 points

_Feedback:_ Excellent. You correctly applied UMAP (fit on train, transform train/test), evaluated KNN across dimensions, and provided a clear 2D visualization. Supervised UMAP usage with labels is fine. Parameters are reasonable. No issues found.

**Part ex2-part3** (ex2-part3.answer): 5/6 points

_Feedback:_ Good explanation: you correctly argue UMAP preserves local neighborhoods and outperforms PCA in low dims when class info isn’t in top-variance PCs. You varied dimensionality and interpreted results. For full credit, mention that UMAP often works best with lower n_neighbors.

---

### Exercise 1 (20/20 = 100.0%)

**Part pipeline-part1** (pipeline-part1.code): 4/4 points

_Feedback:_ Good job. You correctly applied PCA to 2 components and plotted a 2D scatter colored by class. This meets the requirements. Minor improvement: add a colorbar for readability (optional).

**Part pipeline-part2** (pipeline-part2.code): 4/4 points

_Feedback:_ Great job. You fit PCA with up to 40 components, computed percent variance explained, and plotted a clear scree plot. Labeling and scaling are appropriate, and the code robustly handles datasets with fewer than 40 features.

**Part pipeline-part3** (pipeline-part3.code): 4/4 points

_Feedback:_ Correct and concise. Using PCA(n_components=0.95) and reporting n_components_ directly computes the number of components for 95% variance. Fits on X_mnist_train as expected. Full credit.

**Part pipeline-part4** (pipeline-part4.code): 4/4 points

_Feedback:_ Excellent. You correctly used the fitted pca95 to reduce the chosen digit, reconstructed it with inverse_transform, and plotted the result. This matches the prior work and the task’s intent to visualize the digit in the reduced-dimensional space.

**Part pipeline-part5** (pipeline-part5.code): 4/4 points

_Feedback:_ Great job. You compared KNN with and without PCA and preserved ~80% variance using n_components=0.80. You correctly transformed train/test with the same PCA and reported accuracies (and dims). Meets the task requirements.

---

## Additional Information

This feedback was automatically generated by the autograder.

**Generated:** 2025-10-28 19:51:41 UTC

If you have questions about your grade, please reach out to the instructor.